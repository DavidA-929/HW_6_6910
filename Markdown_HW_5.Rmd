---
title: 'STAT 6910: HW 5'
author: "David Angeles"
output:
  pdf_document:
    keep_tex: yes
  html_document:
    df_print: paged
fontsize: 12pt
---

```{r, echo=FALSE}
library(pwr)
library("emmeans")
```


## Problem 1

Check the assumptions on the one-way analysis of variance model (3.3.1) for the meat cooking experiment, which was introduced in Exercise 14 of Chap.3. The data were given in Table 3.14. (the order of collection of observations is not available).


```{r, echo=FALSE}
Post_grams <- matrix(c(81, 85, 71, 84, 83, 78, 
                        88, 80, 77, 84, 88, 75, 
                        85, 82, 72,  82, 85, 78,
                        84, 80, 80,  81, 86, 79, 
                        84, 82, 80, 86, 88, 82), 
                          ncol=6,nrow =5, byrow = TRUE)

Post_grams <- matrix(c(Post_grams[,1],Post_grams[,2],Post_grams[,3], 
                       Post_grams[,4],Post_grams[,5],Post_grams[,6], 
                       rep(1,5), rep(2,5),rep(3,5),
                       rep(4,5),rep(5,5),rep(6,5)),
                     ncol = 2,nrow = 30)

```


The data displayed below is represented by the codes 1, 2, 3, 4, 5, and 6 which denote the frying fat content at 10%, 15%, and 20% and the grilling fat content at 10%, 15% and 20% respectively for the post-cooking weight data (in grams) for the meat cooking experiment.

```{r}
colnames(Post_grams) <- c( "Weight", "Code")
Post_grams <- data.frame(Post_grams)
Post_grams$Code <- factor(Post_grams$Code)
summary(Post_grams)
```


```{r}
n_1 <- nrow(Post_grams); n_1
v_1 <- length(unique(Post_grams$Code)); v_1
rs_1 <- tapply(rep(1,n_1) , Post_grams$Code, sum); rs_1
r_i.vector_1 <- rep(rs_1,time =rs_1); r_i.vector_1


Post_weight_model <- aov(Weight ~ Code , data = Post_grams)
anova(Post_weight_model)
anova(Post_weight_model)[2,"Mean Sq"]


weights.fitted <- fitted(Post_weight_model); weights.fitted

weights.raw.resid <- resid(Post_weight_model); weights.raw.resid 

#MSE <- anova(Post_weight_model)[2,"Mean Sq"]; MSE
#std.residuals <- weights.raw.resid/(sqrt(MSE * (1-1/r_i.vector_1))); std.residuals

std.residuals <- rstandard(Post_weight_model)
```

```{r}
par(mfrow = c(2,2))
#Raw Residuals vs. Frying/ Grilling fat content 
plot(as.numeric(Post_grams$Code) , weights.raw.resid, 
     xlab = "Codes", ylab = "Raw Residuals", xaxt = "n",
     lwd = 1.5)
axis(1, at = 1:6, labels = c("1","2","3","4","5","6"))
abline(h=0, col = "red", lty = 2)

#Raw Residuals vs. Fitted Values
plot(weights.fitted , weights.raw.resid, 
     xlab = "Fitted Values", ylab = "Raw Residuals",
     lwd = 1.5)
abline(h=0, col = "red", lty = 2)

#Standardized Residuals vs. Fitted Values
plot(weights.fitted , std.residuals, 
     xlab = "Fitted Values", ylab = "Standardize Residuals",
     lwd = 1.5)
abline(h=0, col = "red", lty = 2)

#Norma Probability Plot
qqnorm(weights.raw.resid, main= "Normal Q-Q Plot of Raw Residuals")
qqline(weights.raw.resid, col = "red")
```


Assuption (a): The error have mean 0:

Due to the formulation of the One Way ANOVA Model, the residuals always sum up to 0.

Assuption (b): The error have constant variance:

By plotting the residuals against the fitted values of hte treatment levels we saw no big difference in the pattern of the spread within the groups. So we feel comfortable that the equal variance assumption is approximately satisfied.

Since the the samples sizes of each group is equal, we can see that the the expected result is strengthens the assumption.


Assuption (c): The error are nrmally distributed:

From the qq-plot above we see that the data is fairly straight and no outliers are apparent. Therefore the normality assumption is reasonable.


Assuption (d): The error are independent:

Since we do not have any information on the 



## Problem 2

The spaghetti sauce experiment was run to compare the thicknesses of three particular brands of spaghetti sauce, both when stirred and unstirred. The six treatments were:

\begin{center}
1 = store brand, unstirred 2 = store brand, stirred\\
3 = national brand, unstirred 4 = national brand, stirred \\ 
5=gourmet brand,unstirred 6=gourmet brand,stirred
\end{center}

Part of the data collected is shown in Table 5.22. There are three observations per treatment, and the response variable is the weight (in grams) of sauce that flowed through a colander in a given period of time. A thicker sauce would give rise to smaller weights.

(a) Check the assumptions on the one-way analysis of variance model (3.3.1).


```{r}
spaghetti.data = read.table("~/Desktop/Stats 6910/HW_4_and_5/spaghetti.sauce.txt", header = TRUE)

spaghetti.model = aov(weight ~ factor(trtmt), spaghetti.data)
# Compute predicted values, residuals, standardized residuals, normal scores
spaghetti.data = within(spaghetti.data, {
  # Compute predicted, residual, and standardized residual values
  ypred = fitted(spaghetti.model)
  e = resid(spaghetti.model) 
  z = rstandard(spaghetti.model)})
# Display first 10 lines of mung.data, 4 digits per variable
print(head(spaghetti.data, 10), digits=4)


# Generate residual plots


plot(z ~ trtmt, data=spaghetti.data, ylab="Standardized Residuals", las=1)
abline(h=0)  # Horizontal line at zero
plot(z ~ order, data=spaghetti.data, ylab="Standardized Residuals", las=1)
abline(h=0)
plot(z ~ ypred, data=spaghetti.data, ylab="Standardized Residuals", las=1)
abline(h=0)
qqnorm(spaghetti.data$z)
# Line through 1st and 3rd quantile points
qqline(spaghetti.data$z) 


# Compute sample means and variances and their natural logs by trtmt
MeanWeight = by(spaghetti.data$weight, spaghetti.data$trtmt, mean) # Sample means
VarWeight = by(spaghetti.data$weight, spaghetti.data$trtmt, var) # Sample variances
LnMean = log(MeanWeight)  # Column of ln sample means
LnVar = log(VarWeight)  # Column of ln sample variances
Trtmt = c(1:6)  # Column of trtmt levels
stats = cbind(Trtmt, MeanWeight, VarWeight, LnMean, LnVar) # Column bind
stats  # Display the stats data
```



(b) Use Satterthwaiteâ€™s method to obtain simultaneous confidence intervals for the six preplanned contrasts

$$\tau_1 -\tau_2, \tau_3 -\tau_4, \tau_5 -\tau_6, \tau_1 -\tau_5, \tau_1 -\tau_3, \tau_3 -\tau_5,$$


Select an overall confidence level of at least 95%.


We will use Tukey's since we want a simultaneous confidence intervals for the six preplanned contrasts. Therefore,

A simultaius confidence interval for $\tau_1 -\tau_2$ is $(19.63595,-34.96928)$.
A simultaius confidence interval for $\tau_3 -\tau_4$ is $(9.516045,-21.516045)$.
A simultaius confidence interval for $\tau_5 -\tau_6$ is $(11.04009,-11.70676)$.
A simultaius confidence interval for $\tau_1 -\tau_5$ is $(69.58676,15.74657)$.
A simultaius confidence interval for $\tau_1 -\tau_3$ is $(66.07661,15.92339)$.
A simultaius confidence interval for $\tau_3 -\tau_5$ is $(17.18098,-13.84765)$.



The work is shown in the code below.
```{r}
# Fitted values
Y_i_hat <- tapply(spaghetti.data$weight, spaghetti.data$trtmt, mean);
# Sample Variance
Y_i_var <- tapply(spaghetti.data$weight, spaghetti.data$trtmt, var);


# Confidence Interval for tau_i - tau_j
CI_Satterthwaite <- function(ti,tj,variance_i,variance_j,r,v){
# Numerator for Degree of Freedom
numerator <- sum(variance_i/r,variance_j/r)^2
# Denominator for Degree of Freedom
denominator <- sum((variance_i/r)^2/(r-1), (variance_j/r)^2/(r-1))
#Degrees of freedom
deg.fr_taui_tauj <- numerator/ denominator
#Standard error
SE <- sqrt(sum(variance_i/r,variance_j/r))
# w_T
w_T <- qtukey(.95,v,deg.fr_taui_tauj)/ sqrt(2)
# tau_i - tau_j
ti_minus_tj <- ti - tj
#return confidence interval
return(CI_ti_minus_tj <-c(ti_minus_tj + w_T * SE,ti_minus_tj - w_T * SE))
}

t_i <- c(1,3,5,1,1,3)
t_j <- c(2,4,6,5,3,5)
CI_ti_minus_tj <- NULL

for (i in 1:6){
CI_ti_minus_tj<-rbind(CI_ti_minus_tj,
CI_Satterthwaite(Y_i_hat[t_i[i]],Y_i_hat[t_j[i]],
                 Y_i_var[t_i[i]],Y_i_var[t_j[i]],3,6)) }


colnames(CI_ti_minus_tj) <- c("Left","Right")
CI_ti_minus_tj
```

