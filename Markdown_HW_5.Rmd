---
title: 'STAT 6910: HW 5'
author: "David Angeles"
output:
  pdf_document:
    keep_tex: yes
  html_document:
    df_print: paged
fontsize: 12pt
---

```{r, echo=FALSE}
library(ggplot2)
library(pwr)
library("emmeans")
```


## Problem 1

Check the assumptions on the one-way analysis of variance model (3.3.1) for the meat cooking experiment, which was introduced in Exercise 14 of Chap.3. The data were given in Table 3.14. (the order of collection of observations is not available).


```{r, echo=FALSE}
Post_grams <- matrix(c(81, 85, 71, 84, 83, 78, 
                        88, 80, 77, 84, 88, 75, 
                        85, 82, 72,  82, 85, 78,
                        84, 80, 80,  81, 86, 79, 
                        84, 82, 80, 86, 88, 82), 
                          ncol=6,nrow =5, byrow = TRUE)

Post_grams <- matrix(c(Post_grams[,1],Post_grams[,2],Post_grams[,3], 
                       Post_grams[,4],Post_grams[,5],Post_grams[,6], 
                       rep(1,5), rep(2,5),rep(3,5),
                       rep(4,5),rep(5,5),rep(6,5)),
                     ncol = 2,nrow = 30)

```


The data displayed below is represented by the codes 1, 2, 3, 4, 5, and 6 which denote the frying fat content at 10%, 15%, and 20% and the grilling fat content at 10%, 15% and 20% respectively for the post-cooking weight data (in grams) for the meat cooking experiment.

```{r}
colnames(Post_grams) <- c( "Weight", "Code")
Post_grams <- data.frame(Post_grams)
Post_grams$Code <- factor(Post_grams$Code)
summary(Post_grams)
```


```{r}
n_1 <- nrow(Post_grams); n_1
v_1 <- length(unique(Post_grams$Code)); v_1
rs_1 <- tapply(rep(1,n_1) , Post_grams$Code, sum); rs_1
r_i.vector_1 <- rep(rs_1,time =rs_1); r_i.vector_1


Post_weight_model <- aov(Weight ~ Code , data = Post_grams)
anova(Post_weight_model)
anova(Post_weight_model)[2,"Mean Sq"]


weights.fitted <- fitted(Post_weight_model); weights.fitted

weights.raw.resid <- resid(Post_weight_model); weights.raw.resid 

#MSE <- anova(Post_weight_model)[2,"Mean Sq"]; MSE
#std.residuals <- weights.raw.resid/(sqrt(MSE * (1-1/r_i.vector_1))); std.residuals

std.residuals <- rstandard(Post_weight_model)
```

```{r}
par(mfrow = c(2,2))
#Raw Residuals vs. Frying/ Grilling fat content 
plot(as.numeric(Post_grams$Code) , weights.raw.resid, 
     xlab = "Codes", ylab = "Raw Residuals", xaxt = "n",
     lwd = 1.5)
axis(1, at = 1:6, labels = c("1","2","3","4","5","6"))
abline(h=0, col = "red", lty = 2)

#Raw Residuals vs. Fitted Values
plot(weights.fitted , weights.raw.resid, 
     xlab = "Fitted Values", ylab = "Raw Residuals",
     lwd = 1.5)
abline(h=0, col = "red", lty = 2)

#Standardized Residuals vs. Fitted Values
plot(weights.fitted , std.residuals, 
     xlab = "Fitted Values", ylab = "Standardize Residuals",
     lwd = 1.5)
abline(h=0, col = "red", lty = 2)

#Norma Probability Plot
qqnorm(weights.raw.resid, main= "Normal Q-Q Plot of Raw Residuals")
qqline(weights.raw.resid, col = "red")
```


Assuption (a): The error have mean 0:

Due to the formulation of the One Way ANOVA Model, the residuals always sum up to 0.

Assuption (b): The error have constant variance:

By plotting the residuals against the fitted values of hte treatment levels we saw no big difference in the pattern of the spread within the groups. So we feel comfortable that the equal variance assumption is approximately satisfied.

Since the the samples sizes of each group is equal, we can see that the the expected result is strengthens the assumption.


Assuption (c): The error are nrmally distributed:

From the qq-plot above we see that the data is fairly straight and no outliers are apparent. Therefore the normality assumption is reasonable.


Assuption (d): The error are independent:

Since we do not have any information on the 



## Problem 2

The spaghetti sauce experiment was run to compare the thicknesses of three particular brands of spaghetti sauce, both when stirred and unstirred. The six treatments were:

\begin{center}
1 = store brand, unstirred 2 = store brand, stirred\\
3 = national brand, unstirred 4 = national brand, stirred \\ 
5=gourmet brand,unstirred 6=gourmet brand,stirred
\end{center}

Part of the data collected is shown in Table 5.22. There are three observations per treatment, and the response variable is the weight (in grams) of sauce that flowed through a colander in a given period of time. A thicker sauce would give rise to smaller weights.

(a) Check the assumptions on the one-way analysis of variance model (3.3.1).


```{r}
spaghetti.sauce.data = read.table("~/Desktop/Stats 6910/HW_4_and_5/spaghetti.sauce.txt", header = TRUE)

spaghetti.sauce.data <- as.data.frame(spaghetti.sauce.data)
spaghetti.sauce.data$trtmt <- as.factor(spaghetti.sauce.data$trtmt)


spaghetti.model <- aov(weight ~ trtmt , data = spaghetti.sauce.data)
anova(spaghetti.model)

# Get fitted values from the model
spaghetti.fitted <- fitted(spaghetti.model); spaghetti.fitted

# Raw Residuals
spaghetti.raw.residuals <- resid(spaghetti.model); spaghetti.raw.residuals

# Standardize residuals 
spaghetti.stand.residuals <- rstandard(spaghetti.model); spaghetti.stand.residuals 


par(mfrow = c(2,2))
#Raw Residuals vs. Frying/ Grilling fat content 
plot(as.numeric(spaghetti.sauce.data$trtmt) , spaghetti.raw.residuals, 
     xlab = "Codes", ylab = "Raw Residuals", xaxt = "n",
     lwd = 1.5)
axis(1, at = 1:6, labels = c("1","2","3","4","5","6"))
abline(h=0, col = "red", lty = 2)

#Raw Residuals vs. Fitted Values
plot(spaghetti.fitted , spaghetti.raw.residuals, 
     xlab = "Fitted Values", ylab = "Raw Residuals",
     lwd = 1.5)
abline(h=0, col = "red", lty = 2)

#Standardized Residuals vs. Fitted Values
plot(spaghetti.fitted , spaghetti.stand.residuals, 
     xlab = "Fitted Values", ylab = "Standardize Residuals",
     lwd = 1.5)
abline(h=0, col = "red", lty = 2)

#Norma Probability Plot
qqnorm(spaghetti.raw.residuals, main= "Normal Q-Q Plot of Raw Residuals")
qqline(weights.raw.resid, col = "red")
```

(b) Use Satterthwaiteâ€™s method to obtain simultaneous confidence intervals for the six preplanned contrasts

$$\tau_1 -\tau_2, \tau_3 -\tau_4, \tau_5 -\tau_6, \tau_1 -\tau_5, \tau_1 -\tau_3, \tau_3 -\tau_5,$$


Select an overall confidence level of at least 95%.


We will use Tukey's since we want a simultaneous confidence intervals for the six preplanned contrasts. Therefore,

A simultaius confidence interval for $\tau_1 -\tau_2$ is $(19.63595,-34.96928)$.
A simultaius confidence interval for $\tau_3 -\tau_4$ is $(9.516045,-21.516045)$.
A simultaius confidence interval for $\tau_5 -\tau_6$ is $(11.04009,-11.70676)$.
A simultaius confidence interval for $\tau_1 -\tau_5$ is $(69.58676,15.74657)$.
A simultaius confidence interval for $\tau_1 -\tau_3$ is $(66.07661,15.92339)$.
A simultaius confidence interval for $\tau_3 -\tau_5$ is $(17.18098,-13.84765)$.



The work is shown in the code below.
```{r}

spaghetti.fitted
t_1 <- spaghetti.fitted[7]; t_1 # tau_1
t_2 <- spaghetti.fitted[2];t_2 # tau_2
t_3 <- spaghetti.fitted[1]; t_3 # tau_3
t_4 <- spaghetti.fitted[3];t_4# tau_4
t_5 <- spaghetti.fitted[6];t_5 # tau_5
t_6 <- spaghetti.fitted[8];t_6 # tau_6

#1st treatment variance
var_1 <- (sd(spaghetti.sauce.data$weight[spaghetti.sauce.data$trtmt ==1]))^2; var_1 
#2nd treatment variance
var_2 <- (sd(spaghetti.sauce.data$weight[spaghetti.sauce.data$trtmt ==2]))^2; var_2
#3rd treatment variance
var_3 <- (sd(spaghetti.sauce.data$weight[spaghetti.sauce.data$trtmt ==3]))^2; var_3
#4th treatment variance
var_4 <- (sd(spaghetti.sauce.data$weight[spaghetti.sauce.data$trtmt ==4]))^2; var_4
#5th treatment variance
var_5 <- (sd(spaghetti.sauce.data$weight[spaghetti.sauce.data$trtmt ==5]))^2; var_5
#6th treatment variance
var_6 <- (sd(spaghetti.sauce.data$weight[spaghetti.sauce.data$trtmt ==6]))^2; var_6


# Confidence Interval for tau_i - tau_j
CI_Satterthwaite <- function(t1,t2,variance_1,variance_2,r,v){
 #t1= 9.33; t2= 9.03;variance_1 = 2.95; variance_2 = 1.29; r= 10; v=4
  
# Numerator for Degree of Freedom
num_1 <- sum(variance_1/r,variance_2/r)^2
# Denominator for Degree of Freedom
den_1 <- sum((variance_1/r)^2/(r-1), (variance_2/r)^2/(r-1))
#Degrees of freedom
deg.fr_tau1_tau2 <- num_1/ den_1
#Standard error
SE_1 <- sqrt(sum(variance_1/r,variance_2/r))
# w_T
w_1 <- qtukey(.95,v,deg.fr_tau1_tau2)/ sqrt(2)
# tau_i - tau_j
t1_min_t2 <- t1 - t2
#return confidence interval
return(CI_t1_min_t2 <-c(t1_min_t2 + w_1 * SE_1,t1_min_t2 - w_1 * SE_1))
}


CI_tau1_min_tau2 <- CI_Satterthwaite(t_1,t_2,var_1,var_2,3,6);CI_tau1_min_tau2
CI_tau3_min_tau4 <- CI_Satterthwaite(t_3,t_4,var_3,var_4,3,6);CI_tau3_min_tau4 
CI_tau5_min_tau6 <- CI_Satterthwaite(t_5,t_6,var_5,var_6,3,6);CI_tau5_min_tau6
CI_tau1_min_tau5 <- CI_Satterthwaite(t_1,t_5,var_1,var_5,3,6);CI_tau1_min_tau5
CI_tau1_min_tau3 <- CI_Satterthwaite(t_1,t_3,var_1,var_3,3,6);CI_tau1_min_tau3
CI_tau3_min_tau5 <- CI_Satterthwaite(t_3,t_5,var_3,var_5,3,6);CI_tau3_min_tau5


```

